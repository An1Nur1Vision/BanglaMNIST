{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as kr\n",
    "\n",
    "\n",
    "y = np.arange(6000)% 10\n",
    "\n",
    "image_path =  [ './BengaliBMP/' + p for p in os.listdir('./BengaliBMP/') ]\n",
    "\n",
    "input_shape=(48, 48, 1)\n",
    "classes=10\n",
    "\n",
    "def imshow(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    \n",
    "# Reads an image then converts it to grayscale\n",
    "def imread(img_path, max_width=48):\n",
    "    x = cv2.imread(img_path)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2GRAY) / 255\n",
    "    pad_width = int ( (max_width - x.shape[0]) / 2 ) \n",
    "    return np.pad(x, pad_width=pad_width, mode='constant', constant_values=[1])\n",
    "\n",
    "\n",
    "def get_train_X(img_path=image_path, size=(48, 48)):\n",
    "    X = np.empty((len(img_path), size[0], size[1]))\n",
    "    for i, path in enumerate(img_path):\n",
    "        X[i] = imread(path)\n",
    "    X = X.reshape(X.shape[0], size[0], size[1], 1)\n",
    "    return X\n",
    "\n",
    "def get_train_Y(categorical=True):\n",
    "    if categorical == True:\n",
    "        return to_categorical(np.arange(6000)% 10)\n",
    "    return np.arange(6000)% 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "Y_train = get_train_Y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 48, 48\n",
    "\n",
    "X_train = get_train_X()\n",
    "x_train = np.reshape(X_train, (X_train.shape[0], img_rows, img_cols, 1))\n",
    "y_train = get_train_Y()\n",
    "\n",
    "x_train, y_train = shuffle(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4019 samples, validate on 1981 samples\n",
      "Epoch 1/12\n",
      "4019/4019 [==============================] - 2s 550us/step - loss: 1.2947 - acc: 0.5778 - val_loss: 0.8095 - val_acc: 0.7269\n",
      "Epoch 2/12\n",
      "4019/4019 [==============================] - 1s 259us/step - loss: 0.3656 - acc: 0.8880 - val_loss: 0.2087 - val_acc: 0.9384\n",
      "Epoch 3/12\n",
      "4019/4019 [==============================] - 1s 263us/step - loss: 0.2304 - acc: 0.9251 - val_loss: 0.1915 - val_acc: 0.9389\n",
      "Epoch 4/12\n",
      "4019/4019 [==============================] - 1s 264us/step - loss: 0.1696 - acc: 0.9435 - val_loss: 0.2132 - val_acc: 0.9248\n",
      "Epoch 5/12\n",
      "4019/4019 [==============================] - 1s 272us/step - loss: 0.1455 - acc: 0.9579 - val_loss: 0.1129 - val_acc: 0.9697\n",
      "Epoch 6/12\n",
      "4019/4019 [==============================] - 1s 260us/step - loss: 0.1149 - acc: 0.9649 - val_loss: 0.1013 - val_acc: 0.9707\n",
      "Epoch 7/12\n",
      "4019/4019 [==============================] - 1s 267us/step - loss: 0.0957 - acc: 0.9716 - val_loss: 0.1439 - val_acc: 0.9546\n",
      "Epoch 8/12\n",
      "4019/4019 [==============================] - 1s 266us/step - loss: 0.0880 - acc: 0.9746 - val_loss: 0.0924 - val_acc: 0.9753\n",
      "Epoch 9/12\n",
      "4019/4019 [==============================] - 1s 266us/step - loss: 0.0743 - acc: 0.9766 - val_loss: 0.1100 - val_acc: 0.9647\n",
      "Epoch 10/12\n",
      "4019/4019 [==============================] - 1s 267us/step - loss: 0.0589 - acc: 0.9818 - val_loss: 0.0819 - val_acc: 0.9748\n",
      "Epoch 11/12\n",
      "4019/4019 [==============================] - 1s 264us/step - loss: 0.0480 - acc: 0.9863 - val_loss: 0.0776 - val_acc: 0.9783\n",
      "Epoch 12/12\n",
      "4019/4019 [==============================] - 1s 263us/step - loss: 0.0416 - acc: 0.9888 - val_loss: 0.0827 - val_acc: 0.9783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1edd89bcef0>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = ['./test_output48x48/test_output48x48/' + img for img in os.listdir('./test_output48x48/test_output48x48/')]\n",
    "\n",
    "    \n",
    "    \n",
    "# imshow(imread('./test_output48x48/test_output48x48/9_6_resized.jpg'))\n",
    "img = imread('./test_output48x48/test_output48x48/7_3_resized.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./test_output48x48/test_output48x48/5_6_resized.jpg', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1edd8f49a90>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1edd3c18b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.reshape(img, (1, 48, 48, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image, m=model):\n",
    "    image_path = './test_output48x48/test_output48x48/' + image + '_resized.jpg' \n",
    "    img = cv2.imread(image_path, 0)\n",
    "    img = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    img = img / 255\n",
    "    img = np.reshape(img, (1, 48, 48, 1))\n",
    "    return np.argmax(m.predict(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_samples = []\n",
    "for i in range(10):\n",
    "    for j in range(1, 6):\n",
    "        test_image_samples.append(str(i) + '_' + str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real - Predicted : 0 - 5\n",
      "Real - Predicted : 0 - 3\n",
      "Real - Predicted : 0 - 9\n",
      "Real - Predicted : 0 - 3\n",
      "Real - Predicted : 0 - 7\n",
      "Real - Predicted : 1 - 9\n",
      "Real - Predicted : 1 - 1\n",
      "Real - Predicted : 1 - 9\n",
      "Real - Predicted : 1 - 4\n",
      "Real - Predicted : 1 - 9\n",
      "Real - Predicted : 2 - 2\n",
      "Real - Predicted : 2 - 2\n",
      "Real - Predicted : 2 - 2\n",
      "Real - Predicted : 2 - 2\n",
      "Real - Predicted : 2 - 2\n",
      "Real - Predicted : 3 - 3\n",
      "Real - Predicted : 3 - 3\n",
      "Real - Predicted : 3 - 9\n",
      "Real - Predicted : 3 - 7\n",
      "Real - Predicted : 3 - 3\n",
      "Real - Predicted : 4 - 4\n",
      "Real - Predicted : 4 - 4\n",
      "Real - Predicted : 4 - 0\n",
      "Real - Predicted : 4 - 8\n",
      "Real - Predicted : 4 - 4\n",
      "Real - Predicted : 5 - 5\n",
      "Real - Predicted : 5 - 6\n",
      "Real - Predicted : 5 - 7\n",
      "Real - Predicted : 5 - 6\n",
      "Real - Predicted : 5 - 7\n",
      "Real - Predicted : 6 - 6\n",
      "Real - Predicted : 6 - 6\n",
      "Real - Predicted : 6 - 6\n",
      "Real - Predicted : 6 - 6\n",
      "Real - Predicted : 6 - 3\n",
      "Real - Predicted : 7 - 7\n",
      "Real - Predicted : 7 - 7\n",
      "Real - Predicted : 7 - 7\n",
      "Real - Predicted : 7 - 8\n",
      "Real - Predicted : 7 - 7\n",
      "Real - Predicted : 8 - 8\n",
      "Real - Predicted : 8 - 8\n",
      "Real - Predicted : 8 - 8\n",
      "Real - Predicted : 8 - 8\n",
      "Real - Predicted : 8 - 8\n",
      "Real - Predicted : 9 - 9\n",
      "Real - Predicted : 9 - 1\n",
      "Real - Predicted : 9 - 7\n",
      "Real - Predicted : 9 - 7\n",
      "Real - Predicted : 9 - 7\n"
     ]
    }
   ],
   "source": [
    "for test_image in test_image_samples:\n",
    "    print(\"Real - Predicted : {} - {}\".format(test_image.split('_')[0], predict(test_image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0_0',\n",
       " '0_1',\n",
       " '0_2',\n",
       " '0_3',\n",
       " '0_4',\n",
       " '0_5',\n",
       " '1_0',\n",
       " '1_1',\n",
       " '1_2',\n",
       " '1_3',\n",
       " '1_4',\n",
       " '1_5',\n",
       " '2_0',\n",
       " '2_1',\n",
       " '2_2',\n",
       " '2_3',\n",
       " '2_4',\n",
       " '2_5',\n",
       " '3_0',\n",
       " '3_1',\n",
       " '3_2',\n",
       " '3_3',\n",
       " '3_4',\n",
       " '3_5',\n",
       " '4_0',\n",
       " '4_1',\n",
       " '4_2',\n",
       " '4_3',\n",
       " '4_4',\n",
       " '4_5',\n",
       " '5_0',\n",
       " '5_1',\n",
       " '5_2',\n",
       " '5_3',\n",
       " '5_4',\n",
       " '5_5',\n",
       " '6_0',\n",
       " '6_1',\n",
       " '6_2',\n",
       " '6_3',\n",
       " '6_4',\n",
       " '6_5',\n",
       " '7_0',\n",
       " '7_1',\n",
       " '7_2',\n",
       " '7_3',\n",
       " '7_4',\n",
       " '7_5',\n",
       " '8_0',\n",
       " '8_1',\n",
       " '8_2',\n",
       " '8_3',\n",
       " '8_4',\n",
       " '8_5',\n",
       " '9_0',\n",
       " '9_1',\n",
       " '9_2',\n",
       " '9_3',\n",
       " '9_4',\n",
       " '9_5']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CUDA",
   "language": "python",
   "name": "cuda_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
